{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load train/validation/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"../../data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one row with some NaN values in train, we remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245437, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.loc[~ds.order_voucher_percentage__mean.isna(),:]\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_features_cols = [\"customer_id\", \"is_returning_customer\", \"split\"]\n",
    "feature_cols = [c for c in ds.columns if c not in non_features_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(ds):\n",
    "    X = ds[feature_cols] # features\n",
    "    y = ds.is_returning_customer # labels\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_features_and_labels(ds.query(\"split == 'train'\"))\n",
    "X_val, y_val = get_features_and_labels(ds.query(\"split == 'val'\"))\n",
    "X_test, y_test = get_features_and_labels(ds.query(\"split == 'test'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172081, 59), (172081,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24440, 59), (24440,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48916, 59), (48916,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64615829, 0.64615829, 0.64615829, ..., 2.21047426, 0.64615829,\n",
       "       0.64615829])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "#creating Scoring parameter: \n",
    "\n",
    "scoring = {'f1': make_scorer(f1_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172081, 59)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n",
      "CPU times: user 24.2 s, sys: 1.73 s, total: 25.9 s\n",
      "Wall time: 50min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=12345),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1], 'loss': ['deviance'],\n",
       "                         'max_depth': [3, 8], 'max_features': ['log2', 'sqrt'],\n",
       "                         'min_samples_leaf': [20, 50],\n",
       "                         'min_samples_split': [200, 500],\n",
       "                         'n_estimators': [100, 200],\n",
       "                         'n_iter_no_change': [None, 10],\n",
       "                         'subsample': [0.5, 1.0]},\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# A sample parameter\n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"min_samples_split\": [200, 500],\n",
    "    \"min_samples_leaf\": [20, 50],\n",
    "    \"max_depth\":[3, 8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"n_iter_no_change\": [None, 10],\n",
    "    \"subsample\":[0.5, 1.0],\n",
    "    \"n_estimators\":[100, 200]\n",
    "    }\n",
    "#passing the scoring function in the GridSearchCV\n",
    "clf = GridSearchCV(GradientBoostingClassifier(random_state=12345),\n",
    "                   parameters,\n",
    "                   scoring=\"f1\",\n",
    "                   refit=True,\n",
    "                   cv=3,\n",
    "                   n_jobs=-1,\n",
    "                  verbose=10)\n",
    "\n",
    "clf.fit(X_train, y_train, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the clf.cv_results to dataframe\n",
    "cv_res = pd.DataFrame.from_dict(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_n_iter_no_change</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>40.076770</td>\n",
       "      <td>1.303598</td>\n",
       "      <td>0.603188</td>\n",
       "      <td>0.070026</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581028</td>\n",
       "      <td>0.580682</td>\n",
       "      <td>0.588220</td>\n",
       "      <td>0.583310</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>24.630041</td>\n",
       "      <td>0.806103</td>\n",
       "      <td>0.590251</td>\n",
       "      <td>0.026212</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580990</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.588564</td>\n",
       "      <td>0.583267</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>36.631706</td>\n",
       "      <td>2.480807</td>\n",
       "      <td>0.539152</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579818</td>\n",
       "      <td>0.580183</td>\n",
       "      <td>0.589472</td>\n",
       "      <td>0.583157</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>36.691146</td>\n",
       "      <td>2.613661</td>\n",
       "      <td>0.499621</td>\n",
       "      <td>0.034921</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579818</td>\n",
       "      <td>0.580183</td>\n",
       "      <td>0.589472</td>\n",
       "      <td>0.583157</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>25.097409</td>\n",
       "      <td>0.655284</td>\n",
       "      <td>0.621689</td>\n",
       "      <td>0.083683</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581635</td>\n",
       "      <td>0.578453</td>\n",
       "      <td>0.588880</td>\n",
       "      <td>0.582989</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>78.193875</td>\n",
       "      <td>2.798028</td>\n",
       "      <td>1.055936</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581233</td>\n",
       "      <td>0.579606</td>\n",
       "      <td>0.588112</td>\n",
       "      <td>0.582984</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>20.223421</td>\n",
       "      <td>0.309719</td>\n",
       "      <td>0.600116</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581174</td>\n",
       "      <td>0.579159</td>\n",
       "      <td>0.588465</td>\n",
       "      <td>0.582933</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>26.945092</td>\n",
       "      <td>1.569878</td>\n",
       "      <td>0.280071</td>\n",
       "      <td>0.037537</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581084</td>\n",
       "      <td>0.579068</td>\n",
       "      <td>0.588550</td>\n",
       "      <td>0.582901</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>35.030608</td>\n",
       "      <td>1.769471</td>\n",
       "      <td>0.522795</td>\n",
       "      <td>0.067405</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581084</td>\n",
       "      <td>0.579068</td>\n",
       "      <td>0.588550</td>\n",
       "      <td>0.582901</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>63.816994</td>\n",
       "      <td>0.891411</td>\n",
       "      <td>1.108312</td>\n",
       "      <td>0.054456</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581184</td>\n",
       "      <td>0.579255</td>\n",
       "      <td>0.588255</td>\n",
       "      <td>0.582898</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>77.121169</td>\n",
       "      <td>2.127527</td>\n",
       "      <td>1.043782</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.582378</td>\n",
       "      <td>0.578405</td>\n",
       "      <td>0.587848</td>\n",
       "      <td>0.582877</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>48.301163</td>\n",
       "      <td>1.214507</td>\n",
       "      <td>1.121187</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581672</td>\n",
       "      <td>0.579139</td>\n",
       "      <td>0.587701</td>\n",
       "      <td>0.582838</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>65.489072</td>\n",
       "      <td>4.760338</td>\n",
       "      <td>0.509075</td>\n",
       "      <td>0.129561</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580426</td>\n",
       "      <td>0.579645</td>\n",
       "      <td>0.587967</td>\n",
       "      <td>0.582679</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>39.875728</td>\n",
       "      <td>1.084994</td>\n",
       "      <td>0.613593</td>\n",
       "      <td>0.040472</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580403</td>\n",
       "      <td>0.579356</td>\n",
       "      <td>0.588070</td>\n",
       "      <td>0.582610</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>45.471144</td>\n",
       "      <td>0.874769</td>\n",
       "      <td>1.248044</td>\n",
       "      <td>0.080716</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581155</td>\n",
       "      <td>0.578538</td>\n",
       "      <td>0.588133</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>18.609532</td>\n",
       "      <td>0.620577</td>\n",
       "      <td>0.515189</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579056</td>\n",
       "      <td>0.579600</td>\n",
       "      <td>0.589095</td>\n",
       "      <td>0.582584</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>18.821799</td>\n",
       "      <td>1.026740</td>\n",
       "      <td>0.498780</td>\n",
       "      <td>0.026805</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579056</td>\n",
       "      <td>0.579600</td>\n",
       "      <td>0.589095</td>\n",
       "      <td>0.582584</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>42.206671</td>\n",
       "      <td>1.014498</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579707</td>\n",
       "      <td>0.578946</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.582551</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>30.019960</td>\n",
       "      <td>0.991106</td>\n",
       "      <td>0.547592</td>\n",
       "      <td>0.072268</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579697</td>\n",
       "      <td>0.580988</td>\n",
       "      <td>0.586916</td>\n",
       "      <td>0.582534</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>29.623351</td>\n",
       "      <td>0.847824</td>\n",
       "      <td>0.500052</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579697</td>\n",
       "      <td>0.580988</td>\n",
       "      <td>0.586916</td>\n",
       "      <td>0.582534</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>77.589355</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>1.126857</td>\n",
       "      <td>0.064370</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580550</td>\n",
       "      <td>0.578834</td>\n",
       "      <td>0.587701</td>\n",
       "      <td>0.582362</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>46.714886</td>\n",
       "      <td>0.911612</td>\n",
       "      <td>1.117816</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581679</td>\n",
       "      <td>0.578312</td>\n",
       "      <td>0.586946</td>\n",
       "      <td>0.582312</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>24.588391</td>\n",
       "      <td>0.456098</td>\n",
       "      <td>0.606481</td>\n",
       "      <td>0.011901</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580127</td>\n",
       "      <td>0.578699</td>\n",
       "      <td>0.587854</td>\n",
       "      <td>0.582227</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>64.152842</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>1.188002</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580393</td>\n",
       "      <td>0.579396</td>\n",
       "      <td>0.586879</td>\n",
       "      <td>0.582223</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>18.470741</td>\n",
       "      <td>1.590095</td>\n",
       "      <td>0.490514</td>\n",
       "      <td>0.039816</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579164</td>\n",
       "      <td>0.578670</td>\n",
       "      <td>0.588809</td>\n",
       "      <td>0.582214</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>18.069229</td>\n",
       "      <td>2.205428</td>\n",
       "      <td>0.473229</td>\n",
       "      <td>0.072259</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579164</td>\n",
       "      <td>0.578670</td>\n",
       "      <td>0.588809</td>\n",
       "      <td>0.582214</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>62.885508</td>\n",
       "      <td>2.217531</td>\n",
       "      <td>1.066102</td>\n",
       "      <td>0.017625</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580497</td>\n",
       "      <td>0.578559</td>\n",
       "      <td>0.587452</td>\n",
       "      <td>0.582169</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>25.459585</td>\n",
       "      <td>1.380756</td>\n",
       "      <td>0.685621</td>\n",
       "      <td>0.047525</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.578665</td>\n",
       "      <td>0.578627</td>\n",
       "      <td>0.589068</td>\n",
       "      <td>0.582120</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>32.896297</td>\n",
       "      <td>1.228460</td>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579558</td>\n",
       "      <td>0.578254</td>\n",
       "      <td>0.588510</td>\n",
       "      <td>0.582107</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>30.290929</td>\n",
       "      <td>0.337734</td>\n",
       "      <td>0.445240</td>\n",
       "      <td>0.042671</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581408</td>\n",
       "      <td>0.579096</td>\n",
       "      <td>0.585698</td>\n",
       "      <td>0.582067</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>31.349893</td>\n",
       "      <td>1.280519</td>\n",
       "      <td>0.583152</td>\n",
       "      <td>0.110259</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.581408</td>\n",
       "      <td>0.579096</td>\n",
       "      <td>0.585698</td>\n",
       "      <td>0.582067</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>38.804887</td>\n",
       "      <td>0.613462</td>\n",
       "      <td>0.671545</td>\n",
       "      <td>0.094043</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579436</td>\n",
       "      <td>0.579315</td>\n",
       "      <td>0.587210</td>\n",
       "      <td>0.581987</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>49.418481</td>\n",
       "      <td>1.637034</td>\n",
       "      <td>1.226614</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.579019</td>\n",
       "      <td>0.578129</td>\n",
       "      <td>0.588688</td>\n",
       "      <td>0.581945</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>36.971569</td>\n",
       "      <td>3.416722</td>\n",
       "      <td>0.628326</td>\n",
       "      <td>0.049729</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580182</td>\n",
       "      <td>0.577423</td>\n",
       "      <td>0.587956</td>\n",
       "      <td>0.581854</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>24.339103</td>\n",
       "      <td>1.906115</td>\n",
       "      <td>0.643255</td>\n",
       "      <td>0.044087</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579251</td>\n",
       "      <td>0.577753</td>\n",
       "      <td>0.588388</td>\n",
       "      <td>0.581797</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>38.534569</td>\n",
       "      <td>0.974994</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0.041131</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580628</td>\n",
       "      <td>0.577729</td>\n",
       "      <td>0.586863</td>\n",
       "      <td>0.581740</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>35.758906</td>\n",
       "      <td>0.737427</td>\n",
       "      <td>0.584357</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579635</td>\n",
       "      <td>0.578547</td>\n",
       "      <td>0.586930</td>\n",
       "      <td>0.581704</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>34.254534</td>\n",
       "      <td>2.022035</td>\n",
       "      <td>0.582411</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579727</td>\n",
       "      <td>0.577423</td>\n",
       "      <td>0.587956</td>\n",
       "      <td>0.581702</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>60.794983</td>\n",
       "      <td>0.363242</td>\n",
       "      <td>1.128172</td>\n",
       "      <td>0.040768</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580751</td>\n",
       "      <td>0.577099</td>\n",
       "      <td>0.587130</td>\n",
       "      <td>0.581660</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>31.362159</td>\n",
       "      <td>1.201866</td>\n",
       "      <td>0.612031</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.578644</td>\n",
       "      <td>0.577514</td>\n",
       "      <td>0.588670</td>\n",
       "      <td>0.581609</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>32.847671</td>\n",
       "      <td>1.707747</td>\n",
       "      <td>0.633142</td>\n",
       "      <td>0.041318</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579509</td>\n",
       "      <td>0.577603</td>\n",
       "      <td>0.587697</td>\n",
       "      <td>0.581603</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>36.842944</td>\n",
       "      <td>0.157960</td>\n",
       "      <td>0.657756</td>\n",
       "      <td>0.088199</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579277</td>\n",
       "      <td>0.578547</td>\n",
       "      <td>0.586793</td>\n",
       "      <td>0.581539</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>38.253223</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>1.108245</td>\n",
       "      <td>0.061713</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580727</td>\n",
       "      <td>0.577525</td>\n",
       "      <td>0.586154</td>\n",
       "      <td>0.581469</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>33.118636</td>\n",
       "      <td>1.237278</td>\n",
       "      <td>0.621510</td>\n",
       "      <td>0.032145</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579817</td>\n",
       "      <td>0.578161</td>\n",
       "      <td>0.586395</td>\n",
       "      <td>0.581458</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>41.142456</td>\n",
       "      <td>0.730120</td>\n",
       "      <td>0.639287</td>\n",
       "      <td>0.077563</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.577908</td>\n",
       "      <td>0.578638</td>\n",
       "      <td>0.587691</td>\n",
       "      <td>0.581413</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>19.131109</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.640780</td>\n",
       "      <td>0.023369</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580112</td>\n",
       "      <td>0.576931</td>\n",
       "      <td>0.587005</td>\n",
       "      <td>0.581349</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>40.150228</td>\n",
       "      <td>1.286733</td>\n",
       "      <td>1.111588</td>\n",
       "      <td>0.087143</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.580593</td>\n",
       "      <td>0.575927</td>\n",
       "      <td>0.587419</td>\n",
       "      <td>0.581313</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>19.783608</td>\n",
       "      <td>0.602562</td>\n",
       "      <td>0.588862</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.10</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.579577</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>0.587762</td>\n",
       "      <td>0.581298</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>43.670346</td>\n",
       "      <td>1.253275</td>\n",
       "      <td>0.627344</td>\n",
       "      <td>0.028554</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.578528</td>\n",
       "      <td>0.577896</td>\n",
       "      <td>0.587208</td>\n",
       "      <td>0.581211</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>41.734604</td>\n",
       "      <td>0.840488</td>\n",
       "      <td>0.597736</td>\n",
       "      <td>0.041233</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.579576</td>\n",
       "      <td>0.577868</td>\n",
       "      <td>0.585931</td>\n",
       "      <td>0.581125</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "241      40.076770      1.303598         0.603188        0.070026   \n",
       "232      24.630041      0.806103         0.590251        0.026212   \n",
       "239      36.631706      2.480807         0.539152        0.027577   \n",
       "235      36.691146      2.613661         0.499621        0.034921   \n",
       "240      25.097409      0.655284         0.621689        0.083683   \n",
       "245      78.193875      2.798028         1.055936        0.039467   \n",
       "208      20.223421      0.309719         0.600116        0.033820   \n",
       "255      26.945092      1.569878         0.280071        0.037537   \n",
       "251      35.030608      1.769471         0.522795        0.067405   \n",
       "221      63.816994      0.891411         1.108312        0.054456   \n",
       "237      77.121169      2.127527         1.043782        0.018079   \n",
       "236      48.301163      1.214507         1.121187        0.032046   \n",
       "253      65.489072      4.760338         0.509075        0.129561   \n",
       "233      39.875728      1.084994         0.613593        0.040472   \n",
       "252      45.471144      0.874769         1.248044        0.080716   \n",
       "246      18.609532      0.620577         0.515189        0.022717   \n",
       "242      18.821799      1.026740         0.498780        0.026805   \n",
       "225      42.206671      1.014498         0.582550        0.004008   \n",
       "227      30.019960      0.991106         0.547592        0.072268   \n",
       "231      29.623351      0.847824         0.500052        0.017049   \n",
       "229      77.589355      0.775644         1.126857        0.064370   \n",
       "244      46.714886      0.911612         1.117816        0.021719   \n",
       "224      24.588391      0.456098         0.606481        0.011901   \n",
       "213      64.152842      0.447963         1.188002        0.072571   \n",
       "226      18.470741      1.590095         0.490514        0.039816   \n",
       "230      18.069229      2.205428         0.473229        0.072259   \n",
       "197      62.885508      2.217531         1.066102        0.017625   \n",
       "98       25.459585      1.380756         0.685621        0.047525   \n",
       "193      32.896297      1.228460         0.612658        0.040123   \n",
       "243      30.290929      0.337734         0.445240        0.042671   \n",
       "247      31.349893      1.280519         0.583152        0.110259   \n",
       "249      38.804887      0.613462         0.671545        0.094043   \n",
       "102      49.418481      1.637034         1.226614        0.074886   \n",
       "199      36.971569      3.416722         0.628326        0.049729   \n",
       "248      24.339103      1.906115         0.643255        0.044087   \n",
       "204      38.534569      0.974994         1.146148        0.041131   \n",
       "219      35.758906      0.737427         0.584357        0.009867   \n",
       "195      34.254534      2.022035         0.582411        0.049383   \n",
       "205      60.794983      0.363242         1.128172        0.040768   \n",
       "201      31.362159      1.201866         0.612031        0.019980   \n",
       "217      32.847671      1.707747         0.633142        0.041318   \n",
       "223      36.842944      0.157960         0.657756        0.088199   \n",
       "196      38.253223      0.489130         1.108245        0.061713   \n",
       "209      33.118636      1.237278         0.621510        0.032145   \n",
       "99       41.142456      0.730120         0.639287        0.077563   \n",
       "200      19.131109      0.021250         0.640780        0.023369   \n",
       "212      40.150228      1.286733         1.111588        0.087143   \n",
       "192      19.783608      0.602562         0.588862        0.051613   \n",
       "115      43.670346      1.253275         0.627344        0.028554   \n",
       "123      41.734604      0.840488         0.597736        0.041233   \n",
       "\n",
       "    param_learning_rate param_loss param_max_depth param_max_features  \\\n",
       "241                0.10   deviance               8               sqrt   \n",
       "232                0.10   deviance               8               sqrt   \n",
       "239                0.10   deviance               8               sqrt   \n",
       "235                0.10   deviance               8               sqrt   \n",
       "240                0.10   deviance               8               sqrt   \n",
       "245                0.10   deviance               8               sqrt   \n",
       "208                0.10   deviance               8               log2   \n",
       "255                0.10   deviance               8               sqrt   \n",
       "251                0.10   deviance               8               sqrt   \n",
       "221                0.10   deviance               8               log2   \n",
       "237                0.10   deviance               8               sqrt   \n",
       "236                0.10   deviance               8               sqrt   \n",
       "253                0.10   deviance               8               sqrt   \n",
       "233                0.10   deviance               8               sqrt   \n",
       "252                0.10   deviance               8               sqrt   \n",
       "246                0.10   deviance               8               sqrt   \n",
       "242                0.10   deviance               8               sqrt   \n",
       "225                0.10   deviance               8               sqrt   \n",
       "227                0.10   deviance               8               sqrt   \n",
       "231                0.10   deviance               8               sqrt   \n",
       "229                0.10   deviance               8               sqrt   \n",
       "244                0.10   deviance               8               sqrt   \n",
       "224                0.10   deviance               8               sqrt   \n",
       "213                0.10   deviance               8               log2   \n",
       "226                0.10   deviance               8               sqrt   \n",
       "230                0.10   deviance               8               sqrt   \n",
       "197                0.10   deviance               8               log2   \n",
       "98                 0.01   deviance               8               sqrt   \n",
       "193                0.10   deviance               8               log2   \n",
       "243                0.10   deviance               8               sqrt   \n",
       "247                0.10   deviance               8               sqrt   \n",
       "249                0.10   deviance               8               sqrt   \n",
       "102                0.01   deviance               8               sqrt   \n",
       "199                0.10   deviance               8               log2   \n",
       "248                0.10   deviance               8               sqrt   \n",
       "204                0.10   deviance               8               log2   \n",
       "219                0.10   deviance               8               log2   \n",
       "195                0.10   deviance               8               log2   \n",
       "205                0.10   deviance               8               log2   \n",
       "201                0.10   deviance               8               log2   \n",
       "217                0.10   deviance               8               log2   \n",
       "223                0.10   deviance               8               log2   \n",
       "196                0.10   deviance               8               log2   \n",
       "209                0.10   deviance               8               log2   \n",
       "99                 0.01   deviance               8               sqrt   \n",
       "200                0.10   deviance               8               log2   \n",
       "212                0.10   deviance               8               log2   \n",
       "192                0.10   deviance               8               log2   \n",
       "115                0.01   deviance               8               sqrt   \n",
       "123                0.01   deviance               8               sqrt   \n",
       "\n",
       "    param_min_samples_leaf param_min_samples_split param_n_estimators  \\\n",
       "241                     50                     200                100   \n",
       "232                     20                     500                100   \n",
       "239                     20                     500                200   \n",
       "235                     20                     500                100   \n",
       "240                     50                     200                100   \n",
       "245                     50                     200                200   \n",
       "208                     50                     200                100   \n",
       "255                     50                     500                200   \n",
       "251                     50                     500                100   \n",
       "221                     50                     500                200   \n",
       "237                     20                     500                200   \n",
       "236                     20                     500                200   \n",
       "253                     50                     500                200   \n",
       "233                     20                     500                100   \n",
       "252                     50                     500                200   \n",
       "246                     50                     200                200   \n",
       "242                     50                     200                100   \n",
       "225                     20                     200                100   \n",
       "227                     20                     200                100   \n",
       "231                     20                     200                200   \n",
       "229                     20                     200                200   \n",
       "244                     50                     200                200   \n",
       "224                     20                     200                100   \n",
       "213                     50                     200                200   \n",
       "226                     20                     200                100   \n",
       "230                     20                     200                200   \n",
       "197                     20                     200                200   \n",
       "98                      20                     200                100   \n",
       "193                     20                     200                100   \n",
       "243                     50                     200                100   \n",
       "247                     50                     200                200   \n",
       "249                     50                     500                100   \n",
       "102                     20                     200                200   \n",
       "199                     20                     200                200   \n",
       "248                     50                     500                100   \n",
       "204                     20                     500                200   \n",
       "219                     50                     500                100   \n",
       "195                     20                     200                100   \n",
       "205                     20                     500                200   \n",
       "201                     20                     500                100   \n",
       "217                     50                     500                100   \n",
       "223                     50                     500                200   \n",
       "196                     20                     200                200   \n",
       "209                     50                     200                100   \n",
       "99                      20                     200                100   \n",
       "200                     20                     500                100   \n",
       "212                     50                     200                200   \n",
       "192                     20                     200                100   \n",
       "115                     50                     200                100   \n",
       "123                     50                     500                100   \n",
       "\n",
       "    param_n_iter_no_change param_subsample  \\\n",
       "241                   None             1.0   \n",
       "232                   None             0.5   \n",
       "239                     10             1.0   \n",
       "235                     10             1.0   \n",
       "240                   None             0.5   \n",
       "245                   None             1.0   \n",
       "208                   None             0.5   \n",
       "255                     10             1.0   \n",
       "251                     10             1.0   \n",
       "221                   None             1.0   \n",
       "237                   None             1.0   \n",
       "236                   None             0.5   \n",
       "253                   None             1.0   \n",
       "233                   None             1.0   \n",
       "252                   None             0.5   \n",
       "246                     10             0.5   \n",
       "242                     10             0.5   \n",
       "225                   None             1.0   \n",
       "227                     10             1.0   \n",
       "231                     10             1.0   \n",
       "229                   None             1.0   \n",
       "244                   None             0.5   \n",
       "224                   None             0.5   \n",
       "213                   None             1.0   \n",
       "226                     10             0.5   \n",
       "230                     10             0.5   \n",
       "197                   None             1.0   \n",
       "98                      10             0.5   \n",
       "193                   None             1.0   \n",
       "243                     10             1.0   \n",
       "247                     10             1.0   \n",
       "249                   None             1.0   \n",
       "102                     10             0.5   \n",
       "199                     10             1.0   \n",
       "248                   None             0.5   \n",
       "204                   None             0.5   \n",
       "219                     10             1.0   \n",
       "195                     10             1.0   \n",
       "205                   None             1.0   \n",
       "201                   None             1.0   \n",
       "217                   None             1.0   \n",
       "223                     10             1.0   \n",
       "196                   None             0.5   \n",
       "209                   None             1.0   \n",
       "99                      10             1.0   \n",
       "200                   None             0.5   \n",
       "212                   None             0.5   \n",
       "192                   None             0.5   \n",
       "115                     10             1.0   \n",
       "123                     10             1.0   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "241  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581028   \n",
       "232  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580990   \n",
       "239  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579818   \n",
       "235  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579818   \n",
       "240  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581635   \n",
       "245  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581233   \n",
       "208  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581174   \n",
       "255  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581084   \n",
       "251  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581084   \n",
       "221  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581184   \n",
       "237  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.582378   \n",
       "236  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581672   \n",
       "253  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580426   \n",
       "233  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580403   \n",
       "252  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581155   \n",
       "246  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579056   \n",
       "242  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579056   \n",
       "225  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579707   \n",
       "227  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579697   \n",
       "231  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579697   \n",
       "229  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580550   \n",
       "244  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581679   \n",
       "224  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580127   \n",
       "213  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580393   \n",
       "226  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579164   \n",
       "230  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579164   \n",
       "197  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580497   \n",
       "98   {'learning_rate': 0.01, 'loss': 'deviance', 'm...           0.578665   \n",
       "193  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579558   \n",
       "243  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581408   \n",
       "247  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.581408   \n",
       "249  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579436   \n",
       "102  {'learning_rate': 0.01, 'loss': 'deviance', 'm...           0.579019   \n",
       "199  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580182   \n",
       "248  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579251   \n",
       "204  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580628   \n",
       "219  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579635   \n",
       "195  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579727   \n",
       "205  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580751   \n",
       "201  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.578644   \n",
       "217  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579509   \n",
       "223  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579277   \n",
       "196  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580727   \n",
       "209  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579817   \n",
       "99   {'learning_rate': 0.01, 'loss': 'deviance', 'm...           0.577908   \n",
       "200  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580112   \n",
       "212  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.580593   \n",
       "192  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...           0.579577   \n",
       "115  {'learning_rate': 0.01, 'loss': 'deviance', 'm...           0.578528   \n",
       "123  {'learning_rate': 0.01, 'loss': 'deviance', 'm...           0.579576   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "241           0.580682           0.588220         0.583310        0.003475   \n",
       "232           0.580247           0.588564         0.583267        0.003758   \n",
       "239           0.580183           0.589472         0.583157        0.004467   \n",
       "235           0.580183           0.589472         0.583157        0.004467   \n",
       "240           0.578453           0.588880         0.582989        0.004363   \n",
       "245           0.579606           0.588112         0.582984        0.003687   \n",
       "208           0.579159           0.588465         0.582933        0.003997   \n",
       "255           0.579068           0.588550         0.582901        0.004079   \n",
       "251           0.579068           0.588550         0.582901        0.004079   \n",
       "221           0.579255           0.588255         0.582898        0.003869   \n",
       "237           0.578405           0.587848         0.582877        0.003871   \n",
       "236           0.579139           0.587701         0.582838        0.003591   \n",
       "253           0.579645           0.587967         0.582679        0.003753   \n",
       "233           0.579356           0.588070         0.582610        0.003885   \n",
       "252           0.578538           0.588133         0.582609        0.004049   \n",
       "246           0.579600           0.589095         0.582584        0.004610   \n",
       "242           0.579600           0.589095         0.582584        0.004610   \n",
       "225           0.578946           0.589000         0.582551        0.004571   \n",
       "227           0.580988           0.586916         0.582534        0.003143   \n",
       "231           0.580988           0.586916         0.582534        0.003143   \n",
       "229           0.578834           0.587701         0.582362        0.003840   \n",
       "244           0.578312           0.586946         0.582312        0.003553   \n",
       "224           0.578699           0.587854         0.582227        0.004021   \n",
       "213           0.579396           0.586879         0.582223        0.003318   \n",
       "226           0.578670           0.588809         0.582214        0.004667   \n",
       "230           0.578670           0.588809         0.582214        0.004667   \n",
       "197           0.578559           0.587452         0.582169        0.003818   \n",
       "98            0.578627           0.589068         0.582120        0.004913   \n",
       "193           0.578254           0.588510         0.582107        0.004558   \n",
       "243           0.579096           0.585698         0.582067        0.002735   \n",
       "247           0.579096           0.585698         0.582067        0.002735   \n",
       "249           0.579315           0.587210         0.581987        0.003694   \n",
       "102           0.578129           0.588688         0.581945        0.004782   \n",
       "199           0.577423           0.587956         0.581854        0.004459   \n",
       "248           0.577753           0.588388         0.581797        0.004700   \n",
       "204           0.577729           0.586863         0.581740        0.003811   \n",
       "219           0.578547           0.586930         0.581704        0.003722   \n",
       "195           0.577423           0.587956         0.581702        0.004521   \n",
       "205           0.577099           0.587130         0.581660        0.004145   \n",
       "201           0.577514           0.588670         0.581609        0.005014   \n",
       "217           0.577603           0.587697         0.581603        0.004379   \n",
       "223           0.578547           0.586793         0.581539        0.003727   \n",
       "196           0.577525           0.586154         0.581469        0.003561   \n",
       "209           0.578161           0.586395         0.581458        0.003556   \n",
       "99            0.578638           0.587691         0.581413        0.004450   \n",
       "200           0.576931           0.587005         0.581349        0.004205   \n",
       "212           0.575927           0.587419         0.581313        0.004719   \n",
       "192           0.576555           0.587762         0.581298        0.004735   \n",
       "115           0.577896           0.587208         0.581211        0.004249   \n",
       "123           0.577868           0.585931         0.581125        0.003469   \n",
       "\n",
       "     rank_test_score  \n",
       "241                1  \n",
       "232                2  \n",
       "239                3  \n",
       "235                3  \n",
       "240                5  \n",
       "245                6  \n",
       "208                7  \n",
       "255                8  \n",
       "251                8  \n",
       "221               10  \n",
       "237               11  \n",
       "236               12  \n",
       "253               13  \n",
       "233               14  \n",
       "252               15  \n",
       "246               16  \n",
       "242               16  \n",
       "225               18  \n",
       "227               19  \n",
       "231               19  \n",
       "229               21  \n",
       "244               22  \n",
       "224               23  \n",
       "213               24  \n",
       "226               25  \n",
       "230               25  \n",
       "197               27  \n",
       "98                28  \n",
       "193               29  \n",
       "243               30  \n",
       "247               30  \n",
       "249               32  \n",
       "102               33  \n",
       "199               34  \n",
       "248               35  \n",
       "204               36  \n",
       "219               37  \n",
       "195               38  \n",
       "205               39  \n",
       "201               40  \n",
       "217               41  \n",
       "223               42  \n",
       "196               43  \n",
       "209               44  \n",
       "99                45  \n",
       "200               46  \n",
       "212               47  \n",
       "192               48  \n",
       "115               49  \n",
       "123               50  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.sort_values(\"mean_test_score\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833096963962175\n",
      "{\n",
      "  \"learning_rate\": 0.1,\n",
      "  \"loss\": \"deviance\",\n",
      "  \"max_depth\": 8,\n",
      "  \"max_features\": \"sqrt\",\n",
      "  \"min_samples_leaf\": 50,\n",
      "  \"min_samples_split\": 200,\n",
      "  \"n_estimators\": 100,\n",
      "  \"n_iter_no_change\": null,\n",
      "  \"subsample\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "best_row = cv_res.loc[cv_res.mean_test_score.argmax(),:]\n",
    "best_params = best_row[\"params\"]\n",
    "best_mean_test_score = best_row[\"mean_test_score\"]\n",
    "print(best_mean_test_score)\n",
    "print(json.dumps(best_params, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5871144084342054"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on validation set\n",
    "y_pred = clf.predict(X_val)\n",
    "f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fitted_clf.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist model\n",
    "from joblib import dump\n",
    "dump(clf, 'fitted_clf.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh-mkt-ds",
   "language": "python",
   "name": "dh-mkt-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
